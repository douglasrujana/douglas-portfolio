// test-llm.ts
import 'dotenv/config'; // Carga automÃ¡ticamente el .env
import { LLMFactory } from '@/infrastructure/adapters/llm/llm-factory';
import {
  HarmCategory,
  HarmBlockThreshold,
} from '@google/generative-ai';

console.log(`API Key cargada: ${process.env.GEMINI_API_KEY ? 'SÃ­, termina en ' + process.env.GEMINI_API_KEY.slice(-4) : 'No'}`);

const llm = LLMFactory.create('gemini', {
  apiKey: process.env.GEMINI_API_KEY!,
  model: 'gemini-2.5-flash'
});

const question = "Hola, Â¿cÃ³mo funciona la arquitectura hexagonal?";

// ðŸ‘‡ DEFINE LA CONFIGURACIÃ“N DE SEGURIDAD
const safetySettings = [
  {
    category: HarmCategory.HARM_CATEGORY_HARASSMENT,
    threshold: HarmBlockThreshold.BLOCK_NONE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_HATE_SPEECH,
    threshold: HarmBlockThreshold.BLOCK_NONE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,
    threshold: HarmBlockThreshold.BLOCK_NONE,
  },
  {
    category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,
    threshold: HarmBlockThreshold.BLOCK_NONE,
  },
];

const response = await llm.generateResponse(
  question,
  undefined,
  { temperature: 0.7, maxTokens: 10000, safetySettings }
);

// âœ… Salida estructurada
console.log("ðŸ§  Pregunta:");
console.log(question);
console.log("\nðŸ“˜ Respuesta:");
console.log(response.content);
console.log(`\nðŸ“Š Tokens usados: ${response.tokensUsed}`);
